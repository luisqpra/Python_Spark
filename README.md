# Big Data y Spark - Ingeniería de Datos con Python y PySpark

Este repositorio contiene material educativo y soluciones de ejercicios relacionados con los cursos de Spark de Udemy y Platzi. El proyecto se centra en los fundamentos de Spark y PySpark, proporcionando notebooks de conceptos y soluciones de ejercicios para cada sección.

## Contenido del Proyecto

### Base de Datos

La base de datos necesaria para ejecutar los ejemplos se encuentra en el siguiente enlace: [Base de Datos en Google Drive](https://drive.google.com/drive/folders/13q6GivdsI_vCRtO6MZ1_rMNzo6SKqfbx?usp=sharing)

### Estructura del Proyecto

- **Recursos**: Contiene códigos de las clases de los cursos de Udemy y Platzi.
- **Notebooks por Sección**:
  - 0 - Inicio de Uso de PySpark
  - 1 - Creación de RDD
  - 2 - Transformaciones de RDD
  - 3 - Acciones RDD
  - 4 - Funciones Avanzadas RDD
  - 5 - Creación de DataFrames
  - 6 - Transformación de DataFrames
  - 7 - Funciones Avanzadas de DataFrames
  - 8 - Funciones Especiales de DataFrames

Cada sección incluye un notebook de conceptos y otro con soluciones a ejercicios prácticos.

## Requisitos

Para ejecutar los notebooks, asegúrate de tener instalado Python y PySpark. Puedes seguir las instrucciones proporcionadas en los cursos mencionados para configurar tu entorno.

## Uso del Proyecto

1. Clona el repositorio a tu máquina local:

   ```bash
   git clone https://github.com/luisqpra/Python_Spark.git
   ```

2. Descarga la base de datos desde el enlace proporcionado.

3. Abre los notebooks en tu entorno de desarrollo favorito y sigue las instrucciones de cada sección.

## Contribuciones

¡Las contribuciones son bienvenidas! Si encuentras errores, mejoras o deseas agregar contenido adicional, no dudes en enviar un pull request.

## Créditos

Este proyecto se basa en los cursos de Spark de Udemy y Platzi. Agradecemos a los instructores por su valioso material educativo.

## Licencia

Este proyecto está bajo la licencia [MIT](LICENSE).

¡Esperamos que encuentres útil este material para aprender y practicar PySpark! ¡Disfruta explorando el mundo del Big Data y Spark!